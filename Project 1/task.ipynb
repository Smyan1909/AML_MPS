{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:55:11.209970100Z",
     "start_time": "2024-10-30T12:55:04.969121900Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:55:11.225371400Z",
     "start_time": "2024-10-30T12:55:11.210973800Z"
    }
   },
   "id": "1a70f234ed37a130"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    id            x0            x1           x2             x3          x4  \\\n0  0.0  14168.823171  10514.380717  3316.149698   94230.695124  102.386606   \n1  1.0  17757.037554           NaN  4101.016273   92959.527633         NaN   \n2  2.0  14226.656663  11029.642499          NaN  124055.600561  100.542483   \n3  3.0   8766.012436   7384.202998  2147.308418  100157.719990  104.855061   \n4  4.0  13801.016418  13269.493652  3408.316953   92048.527786  103.759758   \n\n           x5            x6            x7            x8  ...          x822  \\\n0   92.677127  11108.748199  10866.505510  10837.622093  ...           NaN   \n1   99.855168  10013.959449  10826.607494  10076.101597  ...           NaN   \n2   92.860892           NaN  10492.342868           NaN  ...  10329.704431   \n3  101.929026  10050.049932  10499.521099  10525.030989  ...  10008.251395   \n4   95.789235   9667.353978  10750.783106  10618.800750  ...  10095.782015   \n\n           x823        x824        x825        x826         x827      x828  \\\n0  12352.094085  846.014651  105.132144  102.112809  2090.004260  2.691845   \n1  16198.071494  776.084467  106.385590  103.472030  2474.051881  2.287976   \n2  13976.063780  737.040332  103.671234  109.458246  2656.083281  2.843706   \n3   6212.127347  329.044233  105.084488  104.858546  1097.785204  2.732257   \n4  13772.061493         NaN         NaN  100.369834  2693.053231  2.702908   \n\n          x829         x830          x831  \n0  1234.374109  1000.784475   9285.751272  \n1          NaN  1012.626705  11750.284764  \n2   888.353607  1048.810385   9553.922728  \n3   927.752967  1048.357330           NaN  \n4  1471.354073  1071.284484   9423.533063  \n\n[5 rows x 833 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>...</th>\n      <th>x822</th>\n      <th>x823</th>\n      <th>x824</th>\n      <th>x825</th>\n      <th>x826</th>\n      <th>x827</th>\n      <th>x828</th>\n      <th>x829</th>\n      <th>x830</th>\n      <th>x831</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>14168.823171</td>\n      <td>10514.380717</td>\n      <td>3316.149698</td>\n      <td>94230.695124</td>\n      <td>102.386606</td>\n      <td>92.677127</td>\n      <td>11108.748199</td>\n      <td>10866.505510</td>\n      <td>10837.622093</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>12352.094085</td>\n      <td>846.014651</td>\n      <td>105.132144</td>\n      <td>102.112809</td>\n      <td>2090.004260</td>\n      <td>2.691845</td>\n      <td>1234.374109</td>\n      <td>1000.784475</td>\n      <td>9285.751272</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>17757.037554</td>\n      <td>NaN</td>\n      <td>4101.016273</td>\n      <td>92959.527633</td>\n      <td>NaN</td>\n      <td>99.855168</td>\n      <td>10013.959449</td>\n      <td>10826.607494</td>\n      <td>10076.101597</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>16198.071494</td>\n      <td>776.084467</td>\n      <td>106.385590</td>\n      <td>103.472030</td>\n      <td>2474.051881</td>\n      <td>2.287976</td>\n      <td>NaN</td>\n      <td>1012.626705</td>\n      <td>11750.284764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>14226.656663</td>\n      <td>11029.642499</td>\n      <td>NaN</td>\n      <td>124055.600561</td>\n      <td>100.542483</td>\n      <td>92.860892</td>\n      <td>NaN</td>\n      <td>10492.342868</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>10329.704431</td>\n      <td>13976.063780</td>\n      <td>737.040332</td>\n      <td>103.671234</td>\n      <td>109.458246</td>\n      <td>2656.083281</td>\n      <td>2.843706</td>\n      <td>888.353607</td>\n      <td>1048.810385</td>\n      <td>9553.922728</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>8766.012436</td>\n      <td>7384.202998</td>\n      <td>2147.308418</td>\n      <td>100157.719990</td>\n      <td>104.855061</td>\n      <td>101.929026</td>\n      <td>10050.049932</td>\n      <td>10499.521099</td>\n      <td>10525.030989</td>\n      <td>...</td>\n      <td>10008.251395</td>\n      <td>6212.127347</td>\n      <td>329.044233</td>\n      <td>105.084488</td>\n      <td>104.858546</td>\n      <td>1097.785204</td>\n      <td>2.732257</td>\n      <td>927.752967</td>\n      <td>1048.357330</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>13801.016418</td>\n      <td>13269.493652</td>\n      <td>3408.316953</td>\n      <td>92048.527786</td>\n      <td>103.759758</td>\n      <td>95.789235</td>\n      <td>9667.353978</td>\n      <td>10750.783106</td>\n      <td>10618.800750</td>\n      <td>...</td>\n      <td>10095.782015</td>\n      <td>13772.061493</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.369834</td>\n      <td>2693.053231</td>\n      <td>2.702908</td>\n      <td>1471.354073</td>\n      <td>1071.284484</td>\n      <td>9423.533063</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 833 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('Data\\X_train.csv')\n",
    "y = pd.read_csv('Data\\y_train.csv')\n",
    "X_test = pd.read_csv('Data\\X_test.csv')\n",
    "\n",
    "X.head()\n",
    "#y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:55:11.521027900Z",
     "start_time": "2024-10-30T12:55:11.226376400Z"
    }
   },
   "id": "a12bfc34ce4b83f8"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x211d2557dc0>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X['id'],X['x0'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T19:41:26.574244600Z",
     "start_time": "2024-10-27T19:41:26.451247600Z"
    }
   },
   "id": "f2ec8f02e00ba8e8"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212\n"
     ]
    }
   ],
   "source": [
    "print(len(X['id']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T19:41:27.629416100Z",
     "start_time": "2024-10-27T19:41:27.608319400Z"
    }
   },
   "id": "9af07ffbe8f67694"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X.drop('id', axis=1, inplace=True)\n",
    "y.drop('id', axis=1, inplace=True)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy().ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:55:11.639059600Z",
     "start_time": "2024-10-30T12:55:11.521027900Z"
    }
   },
   "id": "dae01b73711be86e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LassoCV,Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:55:11.714464300Z",
     "start_time": "2024-10-30T12:55:11.613975400Z"
    }
   },
   "id": "74e9a5300753bae0"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def find_best_model(X, y):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define the hyperparameter grid\n",
    "    n_estimators_values = [100, 200]\n",
    "    max_depth_values = [None, 10, 20]\n",
    "    min_samples_split_values = [2, 5]\n",
    "    n_neighbors_values = [2, 3, 4]\n",
    "    n_clusters_values = [3, 4]\n",
    "    contamination_values = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    # Track the best score and corresponding hyperparameters\n",
    "    best_score = -np.inf\n",
    "    best_params = {}\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    i = 0\n",
    "    for contamination in contamination_values:\n",
    "        for n_estimators in n_estimators_values:\n",
    "            for max_depth in max_depth_values:\n",
    "                for min_samples_split in min_samples_split_values:\n",
    "                    for n_neighbors in n_neighbors_values:\n",
    "                        for n_clusters in n_clusters_values:\n",
    "                            accuracies = []\n",
    "                            \n",
    "                            # Perform cross-validation for each combination of hyperparameters\n",
    "                            for train_index, val_index in kf.split(X):\n",
    "                                X_train, X_val = X[train_index], X[val_index]\n",
    "                                y_train, y_val = y[train_index], y[val_index]\n",
    "                                \n",
    "                                \n",
    "                \n",
    "                                # Step 1: Imputation (use n_neighbors as hyperparameter for KNNImputer)\n",
    "                                X_train_imputed, imputer = replace_NaN(X_train, n_neighbors)\n",
    "                                \n",
    "                \n",
    "                                X_val_imputed = imputer.transform(X_val)\n",
    "                \n",
    "                                # Step 3: Normalize features\n",
    "                                X_train_normalized, scaler = normalize_features(X_train_imputed)\n",
    "                                X_val_normalized = scaler.transform(X_val_imputed)\n",
    "                \n",
    "                                # Step 4: Outlier detection (use n_clusters as hyperparameter)\n",
    "                                anomalies1 = detect_outliers_PCA_GMM(X_train_normalized, n_clusters=n_clusters)\n",
    "                                #anomalies2 = detect_outliers_Autoencoders(X_train_normalized)\n",
    "                                anomalies3 = detect_outliers_IsolationForest(X_train_normalized, contamination=contamination)\n",
    "                                \n",
    "                                anomalies = anomalies1 | anomalies3\n",
    "                                \n",
    "                                X_train_final = X_train_normalized[~anomalies]\n",
    "                                y_train_final = y_train[~anomalies]\n",
    "                \n",
    "                                selector = SelectKBest(f_regression, k=200)\n",
    "                                \n",
    "                                X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "                                X_val_normalized = selector.transform(X_val_normalized)\n",
    "                                # Step 5: Train the model\n",
    "                                model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, n_jobs=-1)\n",
    "                                model.fit(X_train_final, y_train_final)\n",
    "                \n",
    "                                # Step 6: Validate the model\n",
    "                                y_pred = model.predict(X_val_normalized)\n",
    "                \n",
    "                                # Step 7: Calculate accuracy (using RÂ² score)\n",
    "                                accuracies.append(r2_score(y_val, y_pred))\n",
    "                \n",
    "                            # Compute the mean RÂ² score for this combination of hyperparameters\n",
    "                            mean_accuracy = np.mean(accuracies)\n",
    "                            \n",
    "                            current_params = {\n",
    "                                'n_estimators': n_estimators,\n",
    "                                'max_depth': max_depth,\n",
    "                                'min_samples_split': min_samples_split,\n",
    "                                'n_neighbors': n_neighbors,\n",
    "                                'n_clusters': n_clusters,\n",
    "                                'contamination': contamination\n",
    "                            }\n",
    "                            \n",
    "                            print(f\"Iteration {i}: {current_params} -> {mean_accuracy}\")\n",
    "                            \n",
    "                            i += 1\n",
    "                            # If the current mean_accuracy is better than the best score, update the best parameters\n",
    "                            if mean_accuracy > best_score:\n",
    "                                best_score = mean_accuracy\n",
    "                                best_params = current_params\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T23:14:41.034939200Z",
     "start_time": "2024-10-27T23:14:41.004554800Z"
    }
   },
   "id": "78e2eff46a5d21fa"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.48296825864358883\n",
      "Iteration 1: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.48279755994331053\n",
      "Iteration 2: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.48582321179888605\n",
      "Iteration 3: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4802356162529472\n",
      "Iteration 4: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.4703647782610165\n",
      "Iteration 5: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.4793200805791237\n",
      "Iteration 6: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4868952235138293\n",
      "Iteration 7: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.48372869798481616\n",
      "Iteration 8: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.4757949773890914\n",
      "Iteration 9: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.47978956877893336\n",
      "Iteration 10: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.47894436834114035\n",
      "Iteration 11: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.479801047387573\n",
      "Iteration 12: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4731732505238148\n",
      "Iteration 13: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.4856615270534669\n",
      "Iteration 14: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.47415908718218774\n",
      "Iteration 15: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.47773933004897967\n",
      "Iteration 16: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.47019557908713994\n",
      "Iteration 17: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.477502120078973\n",
      "Iteration 18: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4813575704167753\n",
      "Iteration 19: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.474246732942054\n",
      "Iteration 20: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.4769398935990267\n",
      "Iteration 21: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4833190225344583\n",
      "Iteration 22: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.4771373596342139\n",
      "Iteration 23: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.47295964301164606\n",
      "Iteration 24: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4909192520093467\n",
      "Iteration 25: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.4910581706317517\n",
      "Iteration 26: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.47836866661812943\n",
      "Iteration 27: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4838815841984882\n",
      "Iteration 28: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.4878501915514698\n",
      "Iteration 29: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.4791826763838817\n",
      "Iteration 30: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.481248864575149\n",
      "Iteration 31: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.48117365368510157\n",
      "Iteration 32: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.47727516425901334\n",
      "Iteration 33: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4813440216022878\n",
      "Iteration 34: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.4795824953773419\n",
      "Iteration 35: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.48320092861200425\n",
      "Iteration 36: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.48741966895427946\n",
      "Iteration 37: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.48489857414465265\n",
      "Iteration 38: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.48656164485178743\n",
      "Iteration 39: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4849702103233323\n",
      "Iteration 40: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.48216733148787816\n",
      "Iteration 41: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.4854963394116365\n",
      "Iteration 42: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4795622310714259\n",
      "Iteration 43: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.4841324738782614\n",
      "Iteration 44: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.48262370079499617\n",
      "Iteration 45: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4842476987681513\n",
      "Iteration 46: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.47748644458399847\n",
      "Iteration 47: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.48190433393029936\n",
      "Iteration 48: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4826307196585641\n",
      "Iteration 49: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.4830977230498016\n",
      "Iteration 50: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.47892412782881755\n",
      "Iteration 51: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.47810263031139344\n",
      "Iteration 52: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.48349701644523657\n",
      "Iteration 53: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.480930906139038\n",
      "Iteration 54: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.47432656692870123\n",
      "Iteration 55: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.4830756228251799\n",
      "Iteration 56: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.47828649183368765\n",
      "Iteration 57: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.48382552126604494\n",
      "Iteration 58: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.47452153138976494\n",
      "Iteration 59: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.47886065062321437\n",
      "Iteration 60: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4825635950919251\n",
      "Iteration 61: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.4881197086873802\n",
      "Iteration 62: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.4894805302427433\n",
      "Iteration 63: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4906671350927492\n",
      "Iteration 64: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.4771663157295363\n",
      "Iteration 65: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.4823776264113385\n",
      "Iteration 66: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 3, 'contamination': 0.01} -> 0.4829069192142142\n",
      "Iteration 67: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 2, 'n_clusters': 4, 'contamination': 0.01} -> 0.48950968731233163\n",
      "Iteration 68: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01} -> 0.484708897627052\n",
      "Iteration 69: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 4, 'contamination': 0.01} -> 0.4812269137024575\n",
      "Iteration 70: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 3, 'contamination': 0.01} -> 0.48164705961575294\n",
      "Iteration 71: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 4, 'n_clusters': 4, 'contamination': 0.01} -> 0.47738754200684647\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m best_params, best_score \u001B[38;5;241m=\u001B[39m \u001B[43mfind_best_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest_params: \u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Best_score: \u001B[39m\u001B[38;5;124m\"\u001B[39m, best_score)\n",
      "Cell \u001B[1;32mIn[75], line 38\u001B[0m, in \u001B[0;36mfind_best_model\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Step 1: Imputation (use n_neighbors as hyperparameter for KNNImputer)\u001B[39;00m\n\u001B[0;32m     35\u001B[0m X_train_imputed, imputer \u001B[38;5;241m=\u001B[39m replace_NaN(X_train, n_neighbors)\n\u001B[1;32m---> 38\u001B[0m X_val_imputed \u001B[38;5;241m=\u001B[39m \u001B[43mimputer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Step 3: Normalize features\u001B[39;00m\n\u001B[0;32m     41\u001B[0m X_train_normalized, scaler \u001B[38;5;241m=\u001B[39m normalize_features(X_train_imputed)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 316\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    318\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    319\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    320\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    321\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    322\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\impute\\_knn.py:367\u001B[0m, in \u001B[0;36mKNNImputer.transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;66;03m# process in fixed-memory chunks\u001B[39;00m\n\u001B[0;32m    359\u001B[0m gen \u001B[38;5;241m=\u001B[39m pairwise_distances_chunked(\n\u001B[0;32m    360\u001B[0m     X[row_missing_idx, :],\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_X,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    365\u001B[0m     reduce_func\u001B[38;5;241m=\u001B[39mprocess_chunk,\n\u001B[0;32m    366\u001B[0m )\n\u001B[1;32m--> 367\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m gen:\n\u001B[0;32m    368\u001B[0m     \u001B[38;5;66;03m# process_chunk modifies X in place. No return value.\u001B[39;00m\n\u001B[0;32m    369\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkeep_empty_features:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2181\u001B[0m, in \u001B[0;36mpairwise_distances_chunked\u001B[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001B[0m\n\u001B[0;32m   2179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce_func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2180\u001B[0m     chunk_size \u001B[38;5;241m=\u001B[39m D_chunk\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m-> 2181\u001B[0m     D_chunk \u001B[38;5;241m=\u001B[39m \u001B[43mreduce_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mD_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2182\u001B[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001B[0;32m   2183\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m D_chunk\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\impute\\_knn.py:330\u001B[0m, in \u001B[0;36mKNNImputer.transform.<locals>.process_chunk\u001B[1;34m(dist_chunk, start)\u001B[0m\n\u001B[0;32m    325\u001B[0m dist_subset \u001B[38;5;241m=\u001B[39m dist_chunk[dist_idx_map[receivers_idx] \u001B[38;5;241m-\u001B[39m start][\n\u001B[0;32m    326\u001B[0m     :, potential_donors_idx\n\u001B[0;32m    327\u001B[0m ]\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# receivers with all nan distances impute with mean\u001B[39;00m\n\u001B[1;32m--> 330\u001B[0m all_nan_dist_mask \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misnan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdist_subset\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mall(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    331\u001B[0m all_nan_receivers_idx \u001B[38;5;241m=\u001B[39m receivers_idx[all_nan_dist_mask]\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m all_nan_receivers_idx\u001B[38;5;241m.\u001B[39msize:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_params, best_score = find_best_model(X, y)\n",
    "\n",
    "print(\"Best_params: \", best_params,\" Best_score: \", best_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T00:00:37.778811Z",
     "start_time": "2024-10-27T23:14:41.474891400Z"
    }
   },
   "id": "970e296b3814aa49"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.08568490379548, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.877630300965393, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.52034742050091, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.119839351547853, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.48259992745079, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.84206299194193, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.19007518655417, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.287255559724144, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.765489495886868, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.599909701038996, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.44327516193516, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.76661937345125, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122.61694886411715, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128.95566009141112, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105.95605347246965, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 131.32158864322992, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 126.2307421135547, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 131.0694775345146, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.29909244265764, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.09927082274589, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.652372502545404, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.978342587084626, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5710760392667, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.752760311263046, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.07661594296678, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.404699731854635, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.550597208115505, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.083572748662846, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.83393231637456, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.98241371688255, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.14364247001413, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.14600280135528, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.63156804324626, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.12602689759842, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 141.23819723658198, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 146.41825593451358, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 134.19840286339968, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109.89517113119473, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120.98498017685415, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116.94162098085144, tolerance: 8.324687041284406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.034934195311507, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.37858376541408, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.889508447355183, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.0257129825186, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.84364735331292, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.132585144667246, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.37086578931667, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.27246948701577, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.20934937510174, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.44536050328315, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.35383548259779, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.96898439038159, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.97615215536825, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.27493701095591, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120.47363406874683, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102.03512138405495, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.62892371173257, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107.12229614273019, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 111.36873272483354, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 126.91016424056397, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122.62426485542164, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.45267385320767, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100.1892761648487, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 118.91357810789304, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105.18500974193648, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106.77689547116279, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 152.16588405876064, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137.4450943424663, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84.57615439018628, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.8741847769652, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 144.82716493595035, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120.215841807365, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159.12598438683563, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 239.7156649796434, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 304.1125176491987, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323.3173042751373, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 256.3076079507591, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 210.97889393758942, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 315.0056460215037, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 426.10476200789117, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.94898528233443, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 383.38832154624197, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 203.44820274393078, tolerance: 8.39955733944954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.455091864048882, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.040133076679922, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.8361273080136, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.780767282247325, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.0135023466828, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.523780497331245, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.18005408584395, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.673277771424182, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.73386171309539, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.05184998189725, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88.32916878900141, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.71848821498133, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 119.83329374018649, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109.6883935075657, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102.99167332330398, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.43344406187225, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 111.43705146287448, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77.19512644854512, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.01026636555525, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82.51193212447288, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.1992462537819, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.47835410083826, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.760825376255525, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.99027100052626, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.87388879473292, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.45542922958339, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94.61789382027018, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.85882331540324, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106.3880616803217, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77.77472584061115, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.32739853470139, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102.34887857394824, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99.35488349574734, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.85450595496332, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.57816921715403, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.41691957848798, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.88858333267035, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54141612519288, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55.63238430591946, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 111.28339815090567, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99.72950320227574, tolerance: 8.36987110091743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.382239787148137, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.54199289672397, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.517368822431308, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.124022273414084, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.121099686479283, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.744413513060863, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.07970493472021, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.26261735008666, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.8802689451768, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.03723975924004, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 113.90197994634036, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.94409815055224, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.18882680500974, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.009582034568666, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.95342732770405, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.563432163851758, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.201160113815604, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.42032938698685, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.23003654013701, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.88833404934303, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.66873572879376, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.54507075490892, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82.29537797432022, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.17417846754506, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.90441781255686, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89.85462143489895, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.72717555110376, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84.76240269117989, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81.48796371670505, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.60183790371775, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.36791101233666, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.799512594107, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.79155246834853, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.01962871624892, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107.4683336956059, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.94677783444786, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.2444220047355, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73.21682735904596, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109.30089315672194, tolerance: 7.979575114678901\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.669644159032032, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.475791938362818, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.467292302721035, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.365579753750353, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.277140139092808, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.976736778724444, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.62054817307944, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.333988154241524, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.442959655470986, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.56684542862058, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.065113784365167, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.92677926307806, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.228679031468346, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.06326230910054, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.21435153530547, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.9387888010624, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.141419083700384, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.53091711322668, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.15932731290013, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.23150288656143, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.78872876899004, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.448424168283964, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.53636005267799, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.14026162441405, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122.60137663855039, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114.68882055762151, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81.44564608066321, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94.78635455618496, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116.33218829094767, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89.9206774280392, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62.354711373262944, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.68282765148615, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.22876604904195, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.47166291340272, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.10855658956461, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.12303867013634, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.11579020299632, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 135.26536765391484, tolerance: 8.18279449541284\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RÂ²: 0.9152032922057874\n",
      "Validation RÂ²: 0.41061653411154386\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Best_params:  {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01}  Best_score:  0.45824414916035056\n",
    "\n",
    "best_params = {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5, 'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01}\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Apply imputation with the best number of neighbors\n",
    "X_train_imputed, imputer = replace_NaN(X_train, best_params['n_neighbors'])\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "\n",
    "# Normalize features\n",
    "X_train_normalized, scaler = normalize_features(X_train_imputed)\n",
    "X_val_normalized = scaler.transform(X_val_imputed)\n",
    "\n",
    "# Detect outliers\n",
    "anomalies1 = detect_outliers_PCA_GMM(X_train_normalized, n_clusters=best_params['n_clusters'])\n",
    "anomalies2 = detect_outliers_Autoencoders(X_train_normalized)\n",
    "anomalies3 = detect_outliers_IsolationForest(X_train_normalized, contamination=best_params['contamination'])\n",
    "anomalies = anomalies1 & anomalies2 & anomalies3\n",
    "\n",
    "\n",
    "\n",
    "# Filter outliers from the training data\n",
    "X_train_final = X_train_normalized[~anomalies]\n",
    "y_train_final = y_train[~anomalies]\n",
    "\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(f_regression, k=100)\n",
    "X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "X_val_final = selector.transform(X_val_normalized)\n",
    "\n",
    "# Alternative feature selection\n",
    "\"\"\"lasso = LassoCV(cv=5, random_state=42)\n",
    "lasso.fit(X_train_final, y_train_final)\n",
    "lasso_coef = lasso.coef_\n",
    "\n",
    "selected_features = np.where(lasso_coef != 0)[0]\n",
    "\n",
    "X_train_final = X_train_final[:, selected_features]\n",
    "X_val_final = X_val_normalized[:, selected_features]\"\"\"\n",
    "\n",
    "# Train and evaluate the final RandomForestRegressor model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluate performance\n",
    "train_r2 = r2_score(y_train_final, model.predict(X_train_final))\n",
    "val_r2 = r2_score(y_val, model.predict(X_val_final))\n",
    "\n",
    "print(\"Training RÂ²:\", train_r2)\n",
    "print(\"Validation RÂ²:\", val_r2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T19:50:54.252135400Z",
     "start_time": "2024-10-27T19:50:13.063112500Z"
    }
   },
   "id": "318962010552a274"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T13:12:49.934269300Z",
     "start_time": "2024-10-30T13:12:49.849173900Z"
    }
   },
   "id": "129dcf933eb7c14f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def tune_gradient_boosting(X, y, param_grid, n_neighbors, n_clusters, contamination):\n",
    "    \"\"\"\n",
    "    Tune the GradientBoostingRegressor model using cross-validation with preprocessing in each fold.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Features (numpy array or pandas DataFrame)\n",
    "    - y: Target values (numpy array or pandas Series)\n",
    "    - param_grid: Dictionary with hyperparameters for GradientBoostingRegressor to tune\n",
    "    - n_neighbors: Number of neighbors for KNNImputer\n",
    "    - n_clusters: Number of clusters for PCA-GMM outlier detection\n",
    "    - contamination: Contamination rate for IsolationForest outlier detection\n",
    "    \n",
    "    Returns:\n",
    "    - best_params: Best parameters for the GradientBoostingRegressor based on cross-validation\n",
    "    - best_score: Best mean RÂ² score achieved\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    best_score = -np.inf\n",
    "    best_params = {}\n",
    "\n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                \n",
    "                # Track accuracies for current hyperparameters\n",
    "                accuracies = []\n",
    "                \n",
    "                # Cross-validation loop with data preprocessing\n",
    "                for train_index, val_index in kf.split(X):\n",
    "                    X_train, X_val = X[train_index], X[val_index]\n",
    "                    y_train, y_val = y[train_index], y[val_index]\n",
    "                    \n",
    "                    # Step 1: Imputation\n",
    "                    X_train_imputed, imputer = replace_NaN(X_train, n_neighbors)\n",
    "                    X_val_imputed = imputer.transform(X_val)\n",
    "    \n",
    "                    # Step 2: Normalize features\n",
    "                    X_train_normalized, scaler = normalize_features(X_train_imputed)\n",
    "                    X_val_normalized = scaler.transform(X_val_imputed)\n",
    "    \n",
    "                    # Step 3: Outlier detection\n",
    "                    anomalies1 = detect_outliers_PCA_GMM(X_train_normalized, n_clusters=n_clusters)\n",
    "                    anomalies2 = detect_outliers_Autoencoders(X_train_normalized)\n",
    "                    anomalies3 = detect_outliers_IsolationForest(X_train_normalized, contamination=contamination)\n",
    "                    \n",
    "                    anomalies = anomalies1 | anomalies2 | anomalies3\n",
    "                    X_train_final = X_train_normalized[~anomalies]\n",
    "                    y_train_final = y_train[~anomalies]\n",
    "    \n",
    "                    # Step 4: Feature selection\n",
    "                    selector = SelectKBest(f_regression, k=500)\n",
    "                    X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "                    X_val_final = selector.transform(X_val_normalized)\n",
    "                    \n",
    "                    # Step 5: Train GradientBoostingRegressor with current hyperparameters\n",
    "                    gbr = GradientBoostingRegressor(\n",
    "                        n_estimators=n_estimators,\n",
    "                        learning_rate=learning_rate,\n",
    "                        max_depth=max_depth,\n",
    "                        random_state=42\n",
    "                    )\n",
    "                    gbr.fit(X_train_final, y_train_final)\n",
    "                    \n",
    "                    # Step 6: Validate the model\n",
    "                    y_pred = gbr.predict(X_val_final)\n",
    "                    accuracies.append(r2_score(y_val, y_pred))\n",
    "                \n",
    "                # Compute the mean RÂ² score for this set of hyperparameters\n",
    "                mean_accuracy = np.mean(accuracies)\n",
    "                \n",
    "                current_params = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "                \n",
    "                print(f\"Params: {current_params}, Mean RÂ²: {mean_accuracy:.4f}\")\n",
    "                \n",
    "                # Update best parameters if the current score is higher\n",
    "                if mean_accuracy > best_score:\n",
    "                    best_score = mean_accuracy\n",
    "                    best_params = current_params\n",
    "\n",
    "    print(f\"\\nBest Parameters: {best_params}, Best Mean RÂ² Score: {best_score:.4f}\")\n",
    "    return best_params, best_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T00:33:02.316073Z",
     "start_time": "2024-10-27T00:33:02.294638Z"
    }
   },
   "id": "3555333015194c68"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 3}, Mean RÂ²: 0.3265\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 5}, Mean RÂ²: 0.3601\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3}, Mean RÂ²: 0.4542\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 5}, Mean RÂ²: 0.4580\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 3}, Mean RÂ²: 0.4145\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 5}, Mean RÂ²: 0.4372\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 3}, Mean RÂ²: 0.4547\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5}, Mean RÂ²: 0.4594\n",
      "\n",
      "Best Parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5}, Best Mean RÂ² Score: 0.4594\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],          # Number of boosting stages\n",
    "    'learning_rate': [0.01, 0.1],        # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [3, 5]                  # Depth of individual trees\n",
    "}\n",
    "\n",
    "# Assuming X and y are your features and target values\n",
    "best_params, best_score = tune_gradient_boosting(X, y, param_grid, n_neighbors=5, n_clusters=3, contamination=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T01:16:23.134991800Z",
     "start_time": "2024-10-27T00:33:17.208677700Z"
    }
   },
   "id": "ff46bd7d8918fdf3"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def tune_extra_trees(X, y, param_grid, n_neighbors, n_clusters, contamination):\n",
    "    \"\"\"\n",
    "    Tune the ExtraTreesRegressor model using cross-validation with preprocessing in each fold.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Features (numpy array or pandas DataFrame)\n",
    "    - y: Target values (numpy array or pandas Series)\n",
    "    - param_grid: Dictionary with hyperparameters for ExtraTreesRegressor to tune\n",
    "    - n_neighbors: Number of neighbors for KNNImputer\n",
    "    - n_clusters: Number of clusters for PCA-GMM outlier detection\n",
    "    - contamination: Contamination rate for IsolationForest outlier detection\n",
    "    \n",
    "    Returns:\n",
    "    - best_params: Best parameters for the ExtraTreesRegressor based on cross-validation\n",
    "    - best_score: Best mean RÂ² score achieved\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    best_score = -np.inf\n",
    "    best_params = {}\n",
    "\n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for min_samples_split in param_grid['min_samples_split']:\n",
    "                    \n",
    "                    # Track accuracies for current hyperparameters\n",
    "                    accuracies = []\n",
    "                    \n",
    "                    # Cross-validation loop with data preprocessing\n",
    "                    for train_index, val_index in kf.split(X):\n",
    "                        X_train, X_val = X[train_index], X[val_index]\n",
    "                        y_train, y_val = y[train_index], y[val_index]\n",
    "                        \n",
    "                        # Step 1: Imputation\n",
    "                        X_train_imputed, imputer = replace_NaN(X_train, n_neighbors)\n",
    "                        X_val_imputed = imputer.transform(X_val)\n",
    "        \n",
    "                        # Step 2: Normalize features\n",
    "                        X_train_normalized, scaler = normalize_features(X_train_imputed)\n",
    "                        X_val_normalized = scaler.transform(X_val_imputed)\n",
    "        \n",
    "                        # Step 3: Outlier detection\n",
    "                        anomalies1 = detect_outliers_PCA_GMM(X_train_normalized, n_clusters=n_clusters)\n",
    "                        anomalies2 = detect_outliers_Autoencoders(X_train_normalized)\n",
    "                        anomalies3 = detect_outliers_IsolationForest(X_train_normalized, contamination=contamination)\n",
    "                        \n",
    "                        anomalies = anomalies1 & anomalies2 & anomalies3\n",
    "                        X_train_final = X_train_normalized[~anomalies]\n",
    "                        y_train_final = y_train[~anomalies]\n",
    "        \n",
    "                        # Step 4: Feature selection\n",
    "                        selector = SelectKBest(f_regression, k=500)\n",
    "                        X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "                        X_val_final = selector.transform(X_val_normalized)\n",
    "                        \n",
    "                        # Step 5: Train ExtraTreesRegressor with current hyperparameters\n",
    "                        etr = ExtraTreesRegressor(\n",
    "                            n_estimators=n_estimators,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_split=min_samples_split,\n",
    "                            random_state=42\n",
    "                        )\n",
    "                        etr.fit(X_train_final, y_train_final)\n",
    "                        \n",
    "                        # Step 6: Validate the model\n",
    "                        y_pred = etr.predict(X_val_final)\n",
    "                        accuracies.append(r2_score(y_val, y_pred))\n",
    "                    \n",
    "                    # Compute the mean RÂ² score for this set of hyperparameters\n",
    "                    mean_accuracy = np.mean(accuracies)\n",
    "                    \n",
    "                    current_params = {\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Params: {current_params}, Mean RÂ²: {mean_accuracy:.4f}\")\n",
    "                    \n",
    "                    # Update best parameters if the current score is higher\n",
    "                    if mean_accuracy > best_score:\n",
    "                        best_score = mean_accuracy\n",
    "                        best_params = current_params\n",
    "\n",
    "    print(f\"\\nBest Parameters: {best_params}, Best Mean RÂ² Score: {best_score:.4f}\")\n",
    "    return best_params, best_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T20:19:36.257320400Z",
     "start_time": "2024-10-27T20:19:36.233525300Z"
    }
   },
   "id": "43e11c55a96033ee"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2}, Mean RÂ²: 0.4602\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 5}, Mean RÂ²: 0.4631\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 10}, Mean RÂ²: 0.4637\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}, Mean RÂ²: 0.4606\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5}, Mean RÂ²: 0.4589\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10}, Mean RÂ²: 0.4607\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2}, Mean RÂ²: 0.4686\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5}, Mean RÂ²: 0.4633\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 10}, Mean RÂ²: 0.4621\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2}, Mean RÂ²: 0.4658\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5}, Mean RÂ²: 0.4671\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10}, Mean RÂ²: 0.4671\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2}, Mean RÂ²: 0.4632\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5}, Mean RÂ²: 0.4612\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10}, Mean RÂ²: 0.4643\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2}, Mean RÂ²: 0.4710\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5}, Mean RÂ²: 0.4673\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 10}, Mean RÂ²: 0.4668\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2}, Mean RÂ²: 0.4678\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 5}, Mean RÂ²: 0.4680\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 10}, Mean RÂ²: 0.4676\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2}, Mean RÂ²: 0.4638\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5}, Mean RÂ²: 0.4626\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 10}, Mean RÂ²: 0.4633\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 2}, Mean RÂ²: 0.4695\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 5}, Mean RÂ²: 0.4673\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m35/35\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Params: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 10}, Mean RÂ²: 0.4681\n",
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2}, Best Mean RÂ² Score: 0.4710\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "best_params, best_score = tune_extra_trees(X, y, param_grid, n_neighbors=5, n_clusters=3, contamination=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T21:58:52.603165500Z",
     "start_time": "2024-10-27T20:19:36.644835700Z"
    }
   },
   "id": "9892d22b46c421b5"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m31/31\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Training RÂ²: 0.9956630293874346\n",
      "Validation RÂ²: 0.5318417676740149\n"
     ]
    }
   ],
   "source": [
    "# Best Parameters Gradient Roosting Regressor : {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5}, Best Mean RÂ² Score: 0.4594\n",
    "# Best Parameters Extra Trees Regressor: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2}, Best Mean RÂ² Score: 0.4710\n",
    "# Combined Models\n",
    "\n",
    "\n",
    "gboost = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "random_forest = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5, random_state=42)\n",
    "xtra_trees = ExtraTreesRegressor(n_estimators=200, max_depth=20, min_samples_split=2, random_state=42)\n",
    "lasso = LassoCV(cv=10, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\"gboost = GradientBoostingRegressor(n_estimators=150, learning_rate=0.2, max_depth=3, random_state=42)\n",
    "random_forest = RandomForestRegressor(n_estimators=150, max_depth=10, min_samples_split=10, random_state=42)\n",
    "xtra_trees = ExtraTreesRegressor(n_estimators=150, max_depth=10, min_samples_split=10, random_state=42)\n",
    "lasso = LassoCV(cv=7, alphas=[0.01, 0.1, 1.0, 10.0], random_state=42)\"\"\"\n",
    "\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('gboost', gboost),\n",
    "        ('random_forest', random_forest),\n",
    "        ('lasso', lasso),\n",
    "        ('etr', xtra_trees)\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=1.0),  # Meta-model\n",
    "    cv=10  # Cross-validation splits for blending\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "best_params = {'n_neighbors': 3, 'n_clusters': 3, 'contamination': 0.01}\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply imputation with the best number of neighbors\n",
    "X_train_imputed, imputer = replace_NaN(X_train, best_params['n_neighbors'])\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "\n",
    "# Normalize features\n",
    "X_train_normalized, scaler = normalize_features(X_train_imputed)\n",
    "X_val_normalized = scaler.transform(X_val_imputed)\n",
    "\n",
    "# Detect outliers\n",
    "anomalies1 = detect_outliers_PCA_GMM(X_train_normalized, n_clusters=best_params['n_clusters'])\n",
    "anomalies2 = detect_outliers_Autoencoders(X_train_normalized)\n",
    "anomalies3 = detect_outliers_IsolationForest(X_train_normalized, contamination=best_params['contamination'])\n",
    "anomalies = anomalies1 | anomalies2 | anomalies3\n",
    "\n",
    "\n",
    "\n",
    "# Filter outliers from the training data\n",
    "X_train_final = X_train_normalized[~anomalies]\n",
    "y_train_final = y_train[~anomalies]\n",
    "\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(f_regression, k=100)\n",
    "X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "X_val_final = selector.transform(X_val_normalized)\n",
    "\n",
    "stacked_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "train_r2 = r2_score(y_train_final, stacked_model.predict(X_train_final))\n",
    "val_r2 = r2_score(y_val, stacked_model.predict(X_val_final))\n",
    "\n",
    "print(\"Training RÂ²:\", train_r2)\n",
    "print(\"Validation RÂ²:\", val_r2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T23:04:54.737785400Z",
     "start_time": "2024-10-27T23:02:21.807023700Z"
    }
   },
   "id": "de3e432a0b0e638"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using a stacked model of tree-based models with XGBoost as the final estimator to increase the performance of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a31b800d208bd2c1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from preprocessing import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:58:28.597138800Z",
     "start_time": "2024-10-30T12:58:28.514964300Z"
    }
   },
   "id": "6fa2bddc8baf3a39"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m, y\n\u001B[0;32m      3\u001B[0m gboost \u001B[38;5;241m=\u001B[39m GradientBoostingRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.05\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      4\u001B[0m random_forest \u001B[38;5;241m=\u001B[39m RandomForestRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, min_samples_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train = X, y\n",
    "\n",
    "gboost = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=15, min_samples_split=2,random_state=42)\n",
    "xtra_trees = ExtraTreesRegressor(n_estimators=150, max_depth=15, min_samples_split=2,random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=Lasso(alpha=0.1), step=1, cv=5, n_jobs=-1,scoring='neg_mean_squared_error')\n",
    "\n",
    "best_params = {'n_neighbors': 5, 'n_clusters': 5, 'contamination': 0.05}\n",
    "\n",
    "stacked_model = make_pipeline(StackingRegressor(\n",
    "    estimators=[\n",
    "        ('random_forest', random_forest),\n",
    "        ('etr', xtra_trees),\n",
    "        ('gboost', gboost),\n",
    "        ('ridge', Ridge(alpha=1.0))\n",
    "    ],\n",
    "    final_estimator=XGBRegressor(\n",
    "        n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42\n",
    "    ),\n",
    "    cv=5,  # Internal cross-validation\n",
    "    n_jobs=-1,\n",
    "    passthrough=True,  # Meta-model\n",
    "))\n",
    "\n",
    "X_train_imputed, imputer = replace_NaN(X_train, best_params['n_neighbors'])\n",
    "#X_train_imputed, imputer = impute_median(X_train)\n",
    "\n",
    "#anomalies1 = detect_outliers_PCA_GMM(X_train_imputed, threshold_percentile=6)\n",
    "anomalies2 = detect_outliers_Autoencoders(X_train_imputed, encoding_dim=16)\n",
    "anomalies3 = detect_outliers_IsolationForest(X_train_imputed, contamination=best_params['contamination'])\n",
    "anomalies4 = detect_outliers_OneClassSVM(X_train_imputed, nu=0.2)\n",
    "anomalies = anomalies2 | anomalies4\n",
    "\n",
    "#print(np.where(anomalies == True))\n",
    "\n",
    "X_train_final = X_train_imputed[~anomalies]\n",
    "y_train_final = y_train[~anomalies]\n",
    "\n",
    "X_train_final, scaler = normalize_features(X_train_final)\n",
    "\n",
    "print(X_train_final.shape)\n",
    "\n",
    "#selector = SelectKBest(mutual_info_regression, k=100)    \n",
    "#X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "\n",
    "rfecv.fit(X_train_final, y_train_final)\n",
    "\n",
    "selected_features = rfecv.support_\n",
    "\n",
    "X_train_final = X_train_final[:, selected_features]\n",
    "score = cross_val_score(stacked_model, X_train_final, y_train_final, cv=5, n_jobs=-1)\n",
    "print(score.mean(), score.std())  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T12:55:01.288242100Z",
     "start_time": "2024-10-30T12:55:01.013333900Z"
    }
   },
   "id": "d87da3cdce1f0854"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model below uses ElasticNet as a final predictor in the stacked model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3c836348692ebb9"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m38/38\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 791us/step\n",
      "(921, 832)\n",
      "0.6682333792859952 0.040143331059990794\n"
     ]
    }
   ],
   "source": [
    "# Test run with Elastic-Net as final predictor in stacked model\n",
    "X_train, y_train = X, y\n",
    "\n",
    "#Best Parameters: {'stackingregressor__svr__epsilon': 0.5, 'stackingregressor__svr__C': 1000, 'stackingregressor__ridge__alpha': 1.0, 'stackingregressor__gboost__max_iter': 100, 'stackingregressor__gboost__max_depth': 10, 'stackingregressor__gboost__learning_rate': 0.2, 'stackingregressor__gboost__l2_regularization': 0, 'stackingregressor__final_estimator__l1_ratio': 0.3, 'stackingregressor__final_estimator__alpha': 0.1, 'stackingregressor__etr__n_estimators': 100, 'stackingregressor__etr__min_samples_split': 2, 'stackingregressor__etr__max_depth': 20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gboost = HistGradientBoostingRegressor(learning_rate=0.2, max_depth=10, max_iter=100, random_state=42)\n",
    "#random_forest = RandomForestRegressor(n_estimators=100, max_depth=15, min_samples_split=2,random_state=42)\n",
    "xtra_trees = ExtraTreesRegressor(n_estimators=100, max_depth=20, min_samples_split=2,random_state=42)\n",
    "svr = SVR(epsilon=0.5, C=1000)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "rfecv = RFECV(estimator=Lasso(alpha=0.1), step=1, cv=5, n_jobs=-1,scoring='r2')\n",
    "\n",
    "stacked_model = make_pipeline(StackingRegressor(\n",
    "    estimators=[\n",
    "        ('etr', xtra_trees),\n",
    "        ('gboost', gboost),\n",
    "        ('ridge', ridge),\n",
    "        ('svr', svr)\n",
    "    ],\n",
    "    final_estimator=ElasticNet(alpha=0.1, l1_ratio=0.3, random_state=42),\n",
    "    cv=5,  # Internal cross-validation\n",
    "    n_jobs=-1,\n",
    "    passthrough=True,  # Meta-model\n",
    "))\n",
    "\n",
    "X_train_imputed, imputer = replace_NaN(X_train, n_neighbors=5)\n",
    "#X_train_imputed, imputer = impute_median(X_train)\n",
    "\n",
    "anomalies1 = detect_outliers_Autoencoders(X_train_imputed, encoding_dim=16)\n",
    "anomalies2 = detect_outliers_OneClassSVM(X_train_imputed, nu=0.2) # original 0.2\n",
    "\n",
    "anomalies = anomalies1 | anomalies2\n",
    "\n",
    "#print(np.where(anomalies == True))\n",
    "\n",
    "X_train_final = X_train_imputed[~anomalies]\n",
    "y_train_final = y_train[~anomalies]\n",
    "\n",
    "X_train_final, scaler = normalize_features(X_train_final)\n",
    "\n",
    "print(X_train_final.shape)\n",
    "\n",
    "#selector = SelectKBest(mutual_info_regression, k=100)    \n",
    "#X_train_final = selector.fit_transform(X_train_final, y_train_final)\n",
    "\n",
    "rfecv.fit(X_train_final, y_train_final)\n",
    "\n",
    "selected_features = rfecv.support_\n",
    "\n",
    "X_train_final = X_train_final[:, selected_features]\n",
    "score = cross_val_score(stacked_model, X_train_final, y_train_final, cv=10, n_jobs=-1)\n",
    "print(score.mean(), score.std())  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T15:05:08.798327300Z",
     "start_time": "2024-10-30T15:04:02.349321400Z"
    }
   },
   "id": "a17426ad3b879df4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning for the XGBoost stacked model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b607f177e3af49"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=5,\n                   estimator=Pipeline(steps=[('stackingregressor',\n                                              StackingRegressor(cv=5,\n                                                                estimators=[('random_forest',\n                                                                             RandomForestRegressor(max_depth=10,\n                                                                                                   min_samples_split=5,\n                                                                                                   random_state=42)),\n                                                                            ('etr',\n                                                                             ExtraTreesRegressor(max_depth=10,\n                                                                                                 random_state=42)),\n                                                                            ('gboost',\n                                                                             GradientBoostingRegressor(random_state=42))],\n                                                                final_estimator=XGBRegressor(base_score=N...\n                                        'stackingregressor__gboost__learning_rate': [0.05,\n                                                                                     0.1,\n                                                                                     0.2],\n                                        'stackingregressor__gboost__max_depth': [3,\n                                                                                 5,\n                                                                                 7],\n                                        'stackingregressor__gboost__n_estimators': [50,\n                                                                                    100,\n                                                                                    150],\n                                        'stackingregressor__random_forest__max_depth': [10,\n                                                                                        15,\n                                                                                        20],\n                                        'stackingregressor__random_forest__min_samples_split': [2,\n                                                                                                5,\n                                                                                                10],\n                                        'stackingregressor__random_forest__n_estimators': [50,\n                                                                                           100,\n                                                                                           150]},\n                   random_state=42, scoring='r2', verbose=2)",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n                   estimator=Pipeline(steps=[(&#x27;stackingregressor&#x27;,\n                                              StackingRegressor(cv=5,\n                                                                estimators=[(&#x27;random_forest&#x27;,\n                                                                             RandomForestRegressor(max_depth=10,\n                                                                                                   min_samples_split=5,\n                                                                                                   random_state=42)),\n                                                                            (&#x27;etr&#x27;,\n                                                                             ExtraTreesRegressor(max_depth=10,\n                                                                                                 random_state=42)),\n                                                                            (&#x27;gboost&#x27;,\n                                                                             GradientBoostingRegressor(random_state=42))],\n                                                                final_estimator=XGBRegressor(base_score=N...\n                                        &#x27;stackingregressor__gboost__learning_rate&#x27;: [0.05,\n                                                                                     0.1,\n                                                                                     0.2],\n                                        &#x27;stackingregressor__gboost__max_depth&#x27;: [3,\n                                                                                 5,\n                                                                                 7],\n                                        &#x27;stackingregressor__gboost__n_estimators&#x27;: [50,\n                                                                                    100,\n                                                                                    150],\n                                        &#x27;stackingregressor__random_forest__max_depth&#x27;: [10,\n                                                                                        15,\n                                                                                        20],\n                                        &#x27;stackingregressor__random_forest__min_samples_split&#x27;: [2,\n                                                                                                5,\n                                                                                                10],\n                                        &#x27;stackingregressor__random_forest__n_estimators&#x27;: [50,\n                                                                                           100,\n                                                                                           150]},\n                   random_state=42, scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5,\n                   estimator=Pipeline(steps=[(&#x27;stackingregressor&#x27;,\n                                              StackingRegressor(cv=5,\n                                                                estimators=[(&#x27;random_forest&#x27;,\n                                                                             RandomForestRegressor(max_depth=10,\n                                                                                                   min_samples_split=5,\n                                                                                                   random_state=42)),\n                                                                            (&#x27;etr&#x27;,\n                                                                             ExtraTreesRegressor(max_depth=10,\n                                                                                                 random_state=42)),\n                                                                            (&#x27;gboost&#x27;,\n                                                                             GradientBoostingRegressor(random_state=42))],\n                                                                final_estimator=XGBRegressor(base_score=N...\n                                        &#x27;stackingregressor__gboost__learning_rate&#x27;: [0.05,\n                                                                                     0.1,\n                                                                                     0.2],\n                                        &#x27;stackingregressor__gboost__max_depth&#x27;: [3,\n                                                                                 5,\n                                                                                 7],\n                                        &#x27;stackingregressor__gboost__n_estimators&#x27;: [50,\n                                                                                    100,\n                                                                                    150],\n                                        &#x27;stackingregressor__random_forest__max_depth&#x27;: [10,\n                                                                                        15,\n                                                                                        20],\n                                        &#x27;stackingregressor__random_forest__min_samples_split&#x27;: [2,\n                                                                                                5,\n                                                                                                10],\n                                        &#x27;stackingregressor__random_forest__n_estimators&#x27;: [50,\n                                                                                           100,\n                                                                                           150]},\n                   random_state=42, scoring=&#x27;r2&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;stackingregressor&#x27;,\n                 StackingRegressor(cv=5,\n                                   estimators=[(&#x27;random_forest&#x27;,\n                                                RandomForestRegressor(max_depth=15,\n                                                                      random_state=42)),\n                                               (&#x27;etr&#x27;,\n                                                ExtraTreesRegressor(max_depth=15,\n                                                                    n_estimators=150,\n                                                                    random_state=42)),\n                                               (&#x27;gboost&#x27;,\n                                                GradientBoostingRegressor(learning_rate=0.05,\n                                                                          max_depth=5,\n                                                                          n_estimators=50,\n                                                                          random_state=42))],\n                                   final_estimator=XGBRegressor(ba...\n                                                                importance_type=None,\n                                                                interaction_constraints=None,\n                                                                learning_rate=0.1,\n                                                                max_bin=None,\n                                                                max_cat_threshold=None,\n                                                                max_cat_to_onehot=None,\n                                                                max_delta_step=None,\n                                                                max_depth=3,\n                                                                max_leaves=None,\n                                                                min_child_weight=None,\n                                                                missing=nan,\n                                                                monotone_constraints=None,\n                                                                multi_strategy=None,\n                                                                n_estimators=50,\n                                                                n_jobs=None,\n                                                                num_parallel_tree=None,\n                                                                random_state=42, ...),\n                                   n_jobs=-1, passthrough=True))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;stackingregressor: StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for stackingregressor: StackingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(cv=5,\n                  estimators=[(&#x27;random_forest&#x27;,\n                               RandomForestRegressor(max_depth=15,\n                                                     random_state=42)),\n                              (&#x27;etr&#x27;,\n                               ExtraTreesRegressor(max_depth=15,\n                                                   n_estimators=150,\n                                                   random_state=42)),\n                              (&#x27;gboost&#x27;,\n                               GradientBoostingRegressor(learning_rate=0.05,\n                                                         max_depth=5,\n                                                         n_estimators=50,\n                                                         random_state=42))],\n                  final_estimator=XGBRegressor(base_score=None, booster=None,\n                                               callbacks=...\n                                               importance_type=None,\n                                               interaction_constraints=None,\n                                               learning_rate=0.1, max_bin=None,\n                                               max_cat_threshold=None,\n                                               max_cat_to_onehot=None,\n                                               max_delta_step=None, max_depth=3,\n                                               max_leaves=None,\n                                               min_child_weight=None,\n                                               missing=nan,\n                                               monotone_constraints=None,\n                                               multi_strategy=None,\n                                               n_estimators=50, n_jobs=None,\n                                               num_parallel_tree=None,\n                                               random_state=42, ...),\n                  n_jobs=-1, passthrough=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=15, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>etr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\">?<span>Documentation for ExtraTreesRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesRegressor(max_depth=15, n_estimators=150, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=50,\n                          random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=50, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper parameter tuning for stacked model above:\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'stackingregressor__random_forest__n_estimators': [50, 100, 150],\n",
    "    'stackingregressor__random_forest__max_depth': [10, 15, 20],\n",
    "    'stackingregressor__random_forest__min_samples_split': [2, 5, 10],\n",
    "\n",
    "    'stackingregressor__etr__n_estimators': [50, 100, 150],\n",
    "    'stackingregressor__etr__max_depth': [10, 15, 20],\n",
    "    'stackingregressor__etr__min_samples_split': [2, 5, 10],\n",
    "\n",
    "    'stackingregressor__gboost__n_estimators': [50, 100, 150],\n",
    "    'stackingregressor__gboost__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'stackingregressor__gboost__max_depth': [3, 5, 7],\n",
    "\n",
    "    'stackingregressor__final_estimator__n_estimators': [50, 100, 150],\n",
    "    'stackingregressor__final_estimator__max_depth': [3, 5, 7],\n",
    "    'stackingregressor__final_estimator__learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV with the stacked model and param grid\n",
    "grid_search = RandomizedSearchCV(estimator=stacked_model, param_distributions=param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=2, random_state=42, n_iter=100)\n",
    "grid_search.fit(X_train_final, y_train_final)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T21:59:06.369295100Z",
     "start_time": "2024-10-29T21:52:14.597673200Z"
    }
   },
   "id": "5120765ac1b00fca"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'stackingregressor__random_forest__n_estimators': 100, 'stackingregressor__random_forest__min_samples_split': 2, 'stackingregressor__random_forest__max_depth': 15, 'stackingregressor__gboost__n_estimators': 50, 'stackingregressor__gboost__max_depth': 5, 'stackingregressor__gboost__learning_rate': 0.05, 'stackingregressor__final_estimator__n_estimators': 50, 'stackingregressor__final_estimator__max_depth': 3, 'stackingregressor__final_estimator__learning_rate': 0.1, 'stackingregressor__etr__n_estimators': 150, 'stackingregressor__etr__min_samples_split': 2, 'stackingregressor__etr__max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T22:00:38.549546900Z",
     "start_time": "2024-10-29T22:00:38.461172500Z"
    }
   },
   "id": "2af4d36980c0c82a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper parameter tuning for the stacked model with Lasso as the final estimator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6e8061d56b3c987"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=10,\n                   estimator=Pipeline(steps=[('stackingregressor',\n                                              StackingRegressor(cv=5,\n                                                                estimators=[('etr',\n                                                                             ExtraTreesRegressor(max_depth=20,\n                                                                                                 n_estimators=150,\n                                                                                                 random_state=42)),\n                                                                            ('gboost',\n                                                                             HistGradientBoostingRegressor(learning_rate=0.01,\n                                                                                                           max_depth=5,\n                                                                                                           random_state=42)),\n                                                                            ('ridge',\n                                                                             Ridge(alpha=10)),\n                                                                            ('svr',\n                                                                             SVR(C=60,\n                                                                                 epsilon=1e-05))],\n                                                                final_estimator=Elas...\n                                        'stackingregressor__gboost__learning_rate': [0.01,\n                                                                                     0.05,\n                                                                                     0.1,\n                                                                                     0.2],\n                                        'stackingregressor__gboost__max_depth': [3,\n                                                                                 5,\n                                                                                 7,\n                                                                                 10],\n                                        'stackingregressor__gboost__max_iter': [100,\n                                                                                200,\n                                                                                300,\n                                                                                400],\n                                        'stackingregressor__ridge__alpha': [0.1,\n                                                                            1.0,\n                                                                            10.0,\n                                                                            50.0,\n                                                                            100.0],\n                                        'stackingregressor__svr__C': [0.1, 1,\n                                                                      10, 50,\n                                                                      100, 500,\n                                                                      1000],\n                                        'stackingregressor__svr__epsilon': [0.001,\n                                                                            0.01,\n                                                                            0.1,\n                                                                            0.5,\n                                                                            1.0]},\n                   random_state=42, scoring='r2', verbose=2)",
      "text/html": "<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n                   estimator=Pipeline(steps=[(&#x27;stackingregressor&#x27;,\n                                              StackingRegressor(cv=5,\n                                                                estimators=[(&#x27;etr&#x27;,\n                                                                             ExtraTreesRegressor(max_depth=20,\n                                                                                                 n_estimators=150,\n                                                                                                 random_state=42)),\n                                                                            (&#x27;gboost&#x27;,\n                                                                             HistGradientBoostingRegressor(learning_rate=0.01,\n                                                                                                           max_depth=5,\n                                                                                                           random_state=42)),\n                                                                            (&#x27;ridge&#x27;,\n                                                                             Ridge(alpha=10)),\n                                                                            (&#x27;svr&#x27;,\n                                                                             SVR(C=60,\n                                                                                 epsilon=1e-05))],\n                                                                final_estimator=Elas...\n                                        &#x27;stackingregressor__gboost__learning_rate&#x27;: [0.01,\n                                                                                     0.05,\n                                                                                     0.1,\n                                                                                     0.2],\n                                        &#x27;stackingregressor__gboost__max_depth&#x27;: [3,\n                                                                                 5,\n                                                                                 7,\n                                                                                 10],\n                                        &#x27;stackingregressor__gboost__max_iter&#x27;: [100,\n                                                                                200,\n                                                                                300,\n                                                                                400],\n                                        &#x27;stackingregressor__ridge__alpha&#x27;: [0.1,\n                                                                            1.0,\n                                                                            10.0,\n                                                                            50.0,\n                                                                            100.0],\n                                        &#x27;stackingregressor__svr__C&#x27;: [0.1, 1,\n                                                                      10, 50,\n                                                                      100, 500,\n                                                                      1000],\n                                        &#x27;stackingregressor__svr__epsilon&#x27;: [0.001,\n                                                                            0.01,\n                                                                            0.1,\n                                                                            0.5,\n                                                                            1.0]},\n                   random_state=42, scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=10,\n                   estimator=Pipeline(steps=[(&#x27;stackingregressor&#x27;,\n                                              StackingRegressor(cv=5,\n                                                                estimators=[(&#x27;etr&#x27;,\n                                                                             ExtraTreesRegressor(max_depth=20,\n                                                                                                 n_estimators=150,\n                                                                                                 random_state=42)),\n                                                                            (&#x27;gboost&#x27;,\n                                                                             HistGradientBoostingRegressor(learning_rate=0.01,\n                                                                                                           max_depth=5,\n                                                                                                           random_state=42)),\n                                                                            (&#x27;ridge&#x27;,\n                                                                             Ridge(alpha=10)),\n                                                                            (&#x27;svr&#x27;,\n                                                                             SVR(C=60,\n                                                                                 epsilon=1e-05))],\n                                                                final_estimator=Elas...\n                                        &#x27;stackingregressor__gboost__learning_rate&#x27;: [0.01,\n                                                                                     0.05,\n                                                                                     0.1,\n                                                                                     0.2],\n                                        &#x27;stackingregressor__gboost__max_depth&#x27;: [3,\n                                                                                 5,\n                                                                                 7,\n                                                                                 10],\n                                        &#x27;stackingregressor__gboost__max_iter&#x27;: [100,\n                                                                                200,\n                                                                                300,\n                                                                                400],\n                                        &#x27;stackingregressor__ridge__alpha&#x27;: [0.1,\n                                                                            1.0,\n                                                                            10.0,\n                                                                            50.0,\n                                                                            100.0],\n                                        &#x27;stackingregressor__svr__C&#x27;: [0.1, 1,\n                                                                      10, 50,\n                                                                      100, 500,\n                                                                      1000],\n                                        &#x27;stackingregressor__svr__epsilon&#x27;: [0.001,\n                                                                            0.01,\n                                                                            0.1,\n                                                                            0.5,\n                                                                            1.0]},\n                   random_state=42, scoring=&#x27;r2&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;stackingregressor&#x27;,\n                 StackingRegressor(cv=5,\n                                   estimators=[(&#x27;etr&#x27;,\n                                                ExtraTreesRegressor(max_depth=20,\n                                                                    random_state=42)),\n                                               (&#x27;gboost&#x27;,\n                                                HistGradientBoostingRegressor(l2_regularization=0,\n                                                                              learning_rate=0.2,\n                                                                              max_depth=10,\n                                                                              random_state=42)),\n                                               (&#x27;ridge&#x27;, Ridge()),\n                                               (&#x27;svr&#x27;,\n                                                SVR(C=1000, epsilon=0.5))],\n                                   final_estimator=ElasticNet(alpha=0.1,\n                                                              l1_ratio=0.3,\n                                                              random_state=42),\n                                   n_jobs=-1, passthrough=True))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;stackingregressor: StackingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingRegressor.html\">?<span>Documentation for stackingregressor: StackingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StackingRegressor(cv=5,\n                  estimators=[(&#x27;etr&#x27;,\n                               ExtraTreesRegressor(max_depth=20,\n                                                   random_state=42)),\n                              (&#x27;gboost&#x27;,\n                               HistGradientBoostingRegressor(l2_regularization=0,\n                                                             learning_rate=0.2,\n                                                             max_depth=10,\n                                                             random_state=42)),\n                              (&#x27;ridge&#x27;, Ridge()),\n                              (&#x27;svr&#x27;, SVR(C=1000, epsilon=0.5))],\n                  final_estimator=ElasticNet(alpha=0.1, l1_ratio=0.3,\n                                             random_state=42),\n                  n_jobs=-1, passthrough=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>etr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\">?<span>Documentation for ExtraTreesRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesRegressor(max_depth=20, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;HistGradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\">?<span>Documentation for HistGradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingRegressor(l2_regularization=0, learning_rate=0.2,\n                              max_depth=10, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>ridge</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>svr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVR<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVR(C=1000, epsilon=0.5)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.3, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    # ExtraTrees parameters\n",
    "    'stackingregressor__etr__n_estimators': [50, 100, 150, 200, 300],\n",
    "    'stackingregressor__etr__max_depth': [10, 15, 20, 25, 30],\n",
    "    'stackingregressor__etr__min_samples_split': [2, 5, 10, 20],\n",
    "    \n",
    "    # HistGradientBoosting parameters\n",
    "    'stackingregressor__gboost__max_iter': [100, 200, 300, 400],\n",
    "    'stackingregressor__gboost__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'stackingregressor__gboost__max_depth': [3, 5, 7, 10],\n",
    "    'stackingregressor__gboost__l2_regularization': [0, 0.1, 0.5, 1.0],  # Regularization options to reduce overfitting\n",
    "    \n",
    "    # Ridge regression parameter\n",
    "    'stackingregressor__ridge__alpha': [0.1, 1.0, 10.0, 50.0, 100.0],\n",
    "    \n",
    "    # SVR parameters with larger jumps for C and epsilon\n",
    "    'stackingregressor__svr__C': [0.1, 1, 10, 50, 100, 500, 1000],\n",
    "    'stackingregressor__svr__epsilon': [1e-3, 0.01, 0.1, 0.5, 1.0],\n",
    "    \n",
    "    # ElasticNet final estimator parameters\n",
    "    'stackingregressor__final_estimator__alpha': np.logspace(-4, 1, 6),  # Range from very low to high regularization\n",
    "    'stackingregressor__final_estimator__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # Balance between L1 and L2\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=stacked_model, param_distributions=param_distributions, cv=10, scoring='r2', n_jobs=-1, verbose=2, random_state=42, n_iter=200)\n",
    "\n",
    "grid_search.fit(X_train_final, y_train_final)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T14:37:43.686229200Z",
     "start_time": "2024-10-30T14:24:38.738882100Z"
    }
   },
   "id": "85d8714eef8af623"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'stackingregressor__svr__epsilon': 0.5, 'stackingregressor__svr__C': 1000, 'stackingregressor__ridge__alpha': 1.0, 'stackingregressor__gboost__max_iter': 100, 'stackingregressor__gboost__max_depth': 10, 'stackingregressor__gboost__learning_rate': 0.2, 'stackingregressor__gboost__l2_regularization': 0, 'stackingregressor__final_estimator__l1_ratio': 0.3, 'stackingregressor__final_estimator__alpha': 0.1, 'stackingregressor__etr__n_estimators': 100, 'stackingregressor__etr__min_samples_split': 2, 'stackingregressor__etr__max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T14:37:52.872451Z",
     "start_time": "2024-10-30T14:37:52.783919600Z"
    }
   },
   "id": "c12fb9ce56b4435"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_PCA = pca.fit_transform(X_train_final)\n",
    "X_train_imputed_PCA = pca.fit_transform(X_train_imputed)\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(X_train_PCA[:,0],X_train_PCA[:,1],'rx')\n",
    "plt.plot(X_train_imputed_PCA[:,0],X_train_imputed_PCA[:,1],'bo')\n",
    "plt.legend(['After anomaly removal','Before anomaly removal'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T22:46:03.740255200Z",
     "start_time": "2024-10-28T22:46:03.677994100Z"
    }
   },
   "id": "fdbc49df441eb6e6"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Submission 2\n",
    "model = stacked_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "#X_test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "#X_test.to_numpy()\n",
    "\n",
    "X_test_normalized = scaler.transform(imputer.transform(X_test))\n",
    "\n",
    "X_test_final = X_test_normalized[:, selected_features]\n",
    "\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "table = pd.DataFrame({'id': np.arange(len(y_pred)), 'y': y_pred.flatten()})\n",
    "\n",
    "table.to_csv('Data\\y_test_pred.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-30T15:05:45.158236900Z",
     "start_time": "2024-10-30T15:05:42.910309200Z"
    }
   },
   "id": "9ef5078895ba49c8"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 70.2358 - val_loss: 68.7363 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 70.1167 - val_loss: 68.7204 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.3878 - val_loss: 68.5597 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 68.4493 - val_loss: 68.1693 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.2045 - val_loss: 67.5822 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 66.0804 - val_loss: 66.8710 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 63.8779 - val_loss: 65.9235 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 61.2078 - val_loss: 63.8399 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 58.4054 - val_loss: 60.7028 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 55.6313 - val_loss: 56.6403 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 51.9154 - val_loss: 53.0686 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 46.4810 - val_loss: 46.8424 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 41.8453 - val_loss: 40.5446 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 36.2430 - val_loss: 33.3723 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 30.6108 - val_loss: 25.6509 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 24.5800 - val_loss: 17.6327 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 18.3782 - val_loss: 11.1747 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 12.4650 - val_loss: 6.8809 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 8.3031 - val_loss: 8.0040 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.5050 - val_loss: 8.7635 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.2756 - val_loss: 6.6184 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.1263 - val_loss: 6.8711 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.0916 - val_loss: 7.3122 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8832 - val_loss: 6.4416 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.2662 - val_loss: 6.2768 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6984 - val_loss: 6.7141 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8151 - val_loss: 7.0515 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5106 - val_loss: 6.7499 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6551 - val_loss: 6.8652 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3733 - val_loss: 6.3905 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2211 - val_loss: 6.2259 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0196 - val_loss: 6.2535 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2601 - val_loss: 6.2937 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2139 - val_loss: 6.2706 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0194 - val_loss: 6.5065 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3067 - val_loss: 6.5064 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8074 - val_loss: 6.3475 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9895 - val_loss: 6.2581 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1460 - val_loss: 6.1464 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2090 - val_loss: 6.1032 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9566 - val_loss: 6.2118 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0818 - val_loss: 6.2501 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0045 - val_loss: 6.1371 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.7915 - val_loss: 6.1415 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.7657 - val_loss: 6.1119 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1440 - val_loss: 6.0900 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0137 - val_loss: 6.0536 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0175 - val_loss: 6.0228 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0420 - val_loss: 5.9518 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9501 - val_loss: 5.9049 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.6649 - val_loss: 5.9077 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0340 - val_loss: 5.9791 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.6663 - val_loss: 5.9388 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9920 - val_loss: 5.8849 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9129 - val_loss: 5.9242 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8026 - val_loss: 5.8741 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8637 - val_loss: 5.7908 - learning_rate: 1.2500e-04\n",
      "Epoch 58/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0128 - val_loss: 5.8802 - learning_rate: 1.2500e-04\n",
      "Epoch 59/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8195 - val_loss: 5.9253 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9165 - val_loss: 5.9185 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.6184 - val_loss: 5.9414 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9522 - val_loss: 6.0144 - learning_rate: 1.2500e-04\n",
      "Epoch 63/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0189 - val_loss: 6.1149 - learning_rate: 6.2500e-05\n",
      "Epoch 64/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8525 - val_loss: 6.0540 - learning_rate: 6.2500e-05\n",
      "Epoch 65/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.5924 - val_loss: 5.9985 - learning_rate: 6.2500e-05\n",
      "Epoch 66/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.6933 - val_loss: 5.9777 - learning_rate: 6.2500e-05\n",
      "Epoch 67/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.5750 - val_loss: 5.9931 - learning_rate: 6.2500e-05\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "Epoch 1/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 70.1771 - val_loss: 68.5351 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 70.1116 - val_loss: 68.4861 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.6157 - val_loss: 68.2828 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 68.9051 - val_loss: 67.8044 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.9592 - val_loss: 67.1171 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 65.9509 - val_loss: 66.0485 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 64.0490 - val_loss: 64.3547 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 61.9618 - val_loss: 62.2591 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 58.3686 - val_loss: 59.2721 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 55.5502 - val_loss: 55.5527 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 51.2410 - val_loss: 51.5310 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 47.1826 - val_loss: 45.8986 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 42.3778 - val_loss: 39.9927 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 36.3825 - val_loss: 34.3038 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 30.6884 - val_loss: 26.8895 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 24.7756 - val_loss: 17.5889 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 18.5052 - val_loss: 9.4505 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 12.0339 - val_loss: 8.8788 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 7.8821 - val_loss: 6.0462 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.7034 - val_loss: 5.9655 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.1871 - val_loss: 6.2361 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8412 - val_loss: 6.2778 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.4023 - val_loss: 6.6819 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7580 - val_loss: 6.0528 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9219 - val_loss: 6.5003 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7492 - val_loss: 6.2177 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4528 - val_loss: 5.7583 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5559 - val_loss: 5.9635 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8031 - val_loss: 5.9542 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6985 - val_loss: 6.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4370 - val_loss: 5.8038 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2162 - val_loss: 5.9314 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1740 - val_loss: 5.8744 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2436 - val_loss: 5.8151 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4789 - val_loss: 5.7301 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5431 - val_loss: 5.7945 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5354 - val_loss: 5.6920 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2530 - val_loss: 5.7568 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3566 - val_loss: 5.7379 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7517 - val_loss: 5.5780 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2367 - val_loss: 5.5269 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3079 - val_loss: 5.5850 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1417 - val_loss: 5.6142 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1507 - val_loss: 5.6093 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2288 - val_loss: 5.6410 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9536 - val_loss: 5.6262 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9565 - val_loss: 5.5825 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.6979 - val_loss: 5.6564 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0931 - val_loss: 5.6817 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1383 - val_loss: 5.5919 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8459 - val_loss: 5.6103 - learning_rate: 1.2500e-04\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "Epoch 1/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 69.8915 - val_loss: 68.6679 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 70.0486 - val_loss: 68.2142 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.1559 - val_loss: 67.7401 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 68.5710 - val_loss: 66.9410 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.3831 - val_loss: 65.9058 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 65.6050 - val_loss: 64.4993 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 63.4995 - val_loss: 62.7676 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 61.7214 - val_loss: 60.4737 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 58.7796 - val_loss: 57.8510 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 54.7700 - val_loss: 54.6049 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 50.8212 - val_loss: 50.9995 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 46.6309 - val_loss: 46.0076 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 41.3856 - val_loss: 40.1975 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 36.7243 - val_loss: 33.8226 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 29.8669 - val_loss: 25.4453 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 24.7795 - val_loss: 19.3630 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 17.1978 - val_loss: 13.1939 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 12.5902 - val_loss: 8.9896 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 8.2615 - val_loss: 9.2522 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.7945 - val_loss: 7.2076 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.4553 - val_loss: 5.8986 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.1816 - val_loss: 7.3514 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.1094 - val_loss: 6.7683 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9948 - val_loss: 6.6576 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9449 - val_loss: 7.5264 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8363 - val_loss: 6.6515 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5305 - val_loss: 5.8024 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5069 - val_loss: 5.8713 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6565 - val_loss: 6.1152 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4728 - val_loss: 5.9047 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6684 - val_loss: 6.0720 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2434 - val_loss: 5.8810 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2383 - val_loss: 6.0082 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1593 - val_loss: 6.0152 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3363 - val_loss: 6.0069 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2324 - val_loss: 5.7531 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4022 - val_loss: 5.7548 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0514 - val_loss: 5.8088 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0691 - val_loss: 5.9283 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4889 - val_loss: 5.6995 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3090 - val_loss: 5.7297 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9085 - val_loss: 5.9587 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1285 - val_loss: 6.0869 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1732 - val_loss: 5.9385 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9709 - val_loss: 5.7631 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1954 - val_loss: 5.9082 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9727 - val_loss: 5.9802 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3565 - val_loss: 6.0270 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1083 - val_loss: 5.9699 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1495 - val_loss: 6.0679 - learning_rate: 1.2500e-04\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "Epoch 1/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 71.0683 - val_loss: 68.9389 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 70.0139 - val_loss: 68.4198 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.2467 - val_loss: 67.7639 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.9640 - val_loss: 67.0865 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.4186 - val_loss: 66.1910 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 65.1927 - val_loss: 64.8185 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 63.5226 - val_loss: 63.3942 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 61.3450 - val_loss: 61.2950 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 58.1195 - val_loss: 58.4763 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 54.6541 - val_loss: 54.8660 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 51.4524 - val_loss: 50.7286 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 47.0319 - val_loss: 45.4237 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 41.4532 - val_loss: 38.7088 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 36.8139 - val_loss: 32.3834 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 30.3206 - val_loss: 25.5613 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 24.4801 - val_loss: 19.5109 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 18.2237 - val_loss: 13.2872 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 12.2272 - val_loss: 11.0419 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 8.4135 - val_loss: 7.8847 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.8529 - val_loss: 6.7311 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6711 - val_loss: 6.9909 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9843 - val_loss: 6.6040 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7683 - val_loss: 7.0400 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9186 - val_loss: 5.8866 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5628 - val_loss: 5.8511 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3659 - val_loss: 5.9972 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8030 - val_loss: 5.9472 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8137 - val_loss: 5.7948 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2377 - val_loss: 6.1351 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4599 - val_loss: 5.8455 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6478 - val_loss: 6.4086 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5900 - val_loss: 6.1258 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0941 - val_loss: 6.1539 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4598 - val_loss: 6.1506 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7233 - val_loss: 5.8407 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1241 - val_loss: 5.8764 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2886 - val_loss: 6.0210 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3225 - val_loss: 5.8248 - learning_rate: 5.0000e-04\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "Epoch 1/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - loss: 70.8766 - val_loss: 68.6268 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.9284 - val_loss: 68.3593 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.2320 - val_loss: 68.0101 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 68.6074 - val_loss: 67.3543 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.5580 - val_loss: 66.8465 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 66.0775 - val_loss: 65.5179 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 64.1680 - val_loss: 63.6465 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 61.8516 - val_loss: 61.0851 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 58.7322 - val_loss: 57.9963 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 55.2143 - val_loss: 55.1285 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 51.9121 - val_loss: 51.1641 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 47.0174 - val_loss: 45.0920 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 42.0757 - val_loss: 39.0991 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 36.4229 - val_loss: 32.9028 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 31.4560 - val_loss: 26.4459 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 24.5156 - val_loss: 19.2001 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 17.9166 - val_loss: 12.1859 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 12.4845 - val_loss: 8.3560 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 7.5710 - val_loss: 8.5496 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.6000 - val_loss: 6.9128 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.3714 - val_loss: 6.6982 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9789 - val_loss: 5.9045 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.9965 - val_loss: 7.2073 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8741 - val_loss: 6.9206 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4390 - val_loss: 6.7135 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6460 - val_loss: 6.3269 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6844 - val_loss: 6.1800 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5323 - val_loss: 6.0102 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.5807 - val_loss: 6.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2213 - val_loss: 6.1564 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0808 - val_loss: 6.2841 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2630 - val_loss: 5.8965 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 5.2085 - val_loss: 6.0065 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 5.1422 - val_loss: 6.1329 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3527 - val_loss: 5.9354 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 5.2973 - val_loss: 6.1387 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2633 - val_loss: 6.1498 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 5.3713 - val_loss: 5.8852 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0242 - val_loss: 5.9245 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9400 - val_loss: 5.8707 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.6495 - val_loss: 5.7979 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9891 - val_loss: 5.8424 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0906 - val_loss: 5.7428 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0012 - val_loss: 5.8040 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.0928 - val_loss: 5.8599 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9782 - val_loss: 5.9043 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.7430 - val_loss: 5.7865 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9832 - val_loss: 5.7916 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.7788 - val_loss: 5.8499 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.9686 - val_loss: 5.8282 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.1132 - val_loss: 5.8994 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8067 - val_loss: 5.8336 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001B[1m26/26\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.8936 - val_loss: 5.7886 - learning_rate: 1.2500e-04\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "Cross-Validated RÂ² Score: 0.5138 Â± 0.0429\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, Add\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define K-Folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_final):\n",
    "    X_train_cv, X_test_cv = X_train_final[train_index], X_train_final[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_final[train_index], y_train_final[test_index]\n",
    "    \n",
    "    # Build and compile the model inside the loop\n",
    "    model_cv = Sequential([\n",
    "        Input(shape=(X_train_cv.shape[1],)),\n",
    "        Dense(512, activation='swish', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='swish', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation='swish',kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model_cv.compile(optimizer=AdamW(learning_rate=0.001), loss='huber')\n",
    "    \n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    # Include in model.fit()\n",
    "    history = model_cv.fit(\n",
    "        X_train_cv, y_train_cv,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Predict and calculate RÂ² score\n",
    "    y_pred_cv = model_cv.predict(X_test_cv).flatten()\n",
    "    r2_cv = r2_score(y_test_cv, y_pred_cv)\n",
    "    r2_scores.append(r2_cv)\n",
    "\n",
    "# Calculate average RÂ² score\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "print(f'Cross-Validated RÂ² Score: {mean_r2:.4f} Â± {std_r2:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T01:01:40.350722300Z",
     "start_time": "2024-10-29T01:01:02.534098400Z"
    }
   },
   "id": "74f2c00817c6f930"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 70.2795 - val_loss: 68.5752 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 69.9272 - val_loss: 68.2338 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 68.9895 - val_loss: 67.6251 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 67.9433 - val_loss: 66.5970 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 66.0875 - val_loss: 65.1146 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 62.8665 - val_loss: 62.8079 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 60.0249 - val_loss: 59.6871 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 55.9410 - val_loss: 55.4070 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 50.5705 - val_loss: 48.9655 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 44.9395 - val_loss: 42.2551 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 37.7148 - val_loss: 33.6841 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 31.0885 - val_loss: 25.0020 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 23.1143 - val_loss: 14.4760 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 15.5380 - val_loss: 8.0675 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 9.0823 - val_loss: 7.0190 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.8615 - val_loss: 7.9431 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.4587 - val_loss: 7.2608 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.4626 - val_loss: 6.8668 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.0793 - val_loss: 6.4529 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8106 - val_loss: 5.9197 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6144 - val_loss: 5.7388 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.8097 - val_loss: 6.1464 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7554 - val_loss: 5.7620 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.6928 - val_loss: 5.8238 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7172 - val_loss: 6.0729 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.7786 - val_loss: 6.0780 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4739 - val_loss: 6.1533 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4891 - val_loss: 5.9902 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.3973 - val_loss: 5.9335 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2290 - val_loss: 5.8066 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001B[1m33/33\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.4603 - val_loss: 5.8074 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smyan\\anaconda3\\envs\\AML_projects\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m25/25\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train_final.shape[1],)),\n",
    "    Dense(512, activation='swish', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='swish', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='swish', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=AdamW(learning_rate=0.001), loss='huber')\n",
    "\n",
    "# Define callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Train the model on the full training data with a validation split for monitoring\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,  # Keep a small validation set for early stopping\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#X_test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "#X_test.to_numpy()\n",
    "\n",
    "X_test_normalized = scaler.transform(imputer.transform(X_test))\n",
    "\n",
    "X_test_final = X_test_normalized[:, selected_features]\n",
    "\n",
    "# Evaluate the model on the test data after training\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "table = pd.DataFrame({'id': np.arange(len(y_pred)), 'y': y_pred.flatten()})\n",
    "\n",
    "table.to_csv('Data\\y_test_pred_nn.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T01:08:14.035522400Z",
     "start_time": "2024-10-29T01:08:07.086114400Z"
    }
   },
   "id": "8e319064205ed68c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aedfc6b0eb8798a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
